{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260c3a63",
   "metadata": {},
   "source": [
    "**2\\. Анализ данных (Data Understanding)**\n",
    "\n",
    "Цель шага – понять слабые и сильные стороны предоставленных данных, определить их достаточность, предложить идеи, как  \n",
    "их использовать, и лучше понять процессы заказчика. Для этого мы строим графики, делаем выборки и рассчитываем  \n",
    "статистики.\n",
    "\n",
    "2.1 Сбор данных (Data collection)  \n",
    "Выгружаем необходимые данные (или срез данных если их объем слишком велик) из источников.  \n",
    "Версионируем данные средствами DVC.\n",
    "\n",
    "2.2 Исследование данных (Data exploration)  \n",
    "Исследуем данные, чтобы сформулировать гипотезы относительно того, как эти данные помогут решить задачу. Проверяем  \n",
    "качество данных.\n",
    "\n",
    "Ориентировочный список для проверки данных:\n",
    "\n",
    "1. Загрузить репрезентативную выборку из набора данных  \n",
    "2. Провести предварительный анализ всей выборки.  \n",
    "* определить тип данных в каждом столбце  \n",
    "* Категориальные данные (Номинальные, Порядковые)  \n",
    "* Числовые данные (дискретные, непрерывные, интервальные, отношения)  \n",
    "* При необходимости преобразовать данные к нужным типам  \n",
    "* Проверить на выбросы, отсутствующие значения, невалидные значения(например в системе случился сбой и в поле с именемпопала длина просмотра).\n",
    "\n",
    "(по результатам предварительного анализа сделать визуализацию, обычно это табличка с характеристиками или какой то из  \n",
    "профайлеров)\n",
    "\n",
    "3. На основе предыдущего анализа выполнить очистку данных (обработать выбросы, отсутствующие значения, удалить невалидные значения)  \n",
    "4. Удалить из рассмотрения неинформативные данные. (лишние идентификаторы, служебные поля, поля с очень малым количеством значений)  \n",
    "5. Провести статистический анализ оставшихся данных  \n",
    "   1. рассчитать ключевые статистики для каждого типа данных  \n",
    "   2. построить распределения (тип графика выбрать в зависимости от данных, часто полезно построить гистограмму, но иногда лучше воспользоваться линейным графиком или посмотреть распределение во времени с помощью scaterplot)  \n",
    "6. Провести корреляционный анализ  \n",
    "   1. Для количественных данных нормализовать данные и построить матрицу корреляции Пирсона  \n",
    "   2. сделать выводы на основе матрицы (найти утечки данных, найти важные признаки линейно влияющие на целевой показатель, определить гипотезы по конструированию признаков)  \n",
    "   3. Для количественных и порядковых данных \\- построить матрицу корреляции Спирмена  сделать выводы аналогично предыдущему анализу, только учесть тип данных  \n",
    "   4. Для всех данных построить матрицу корреляции Пфика  \n",
    "   5. Сделать выводы на основе анализа, сделать оценку между всеми типами корреляции(на пересекающихся данных),  \n",
    "   6. попытаться найти объяснения различиям.  \n",
    "   7. Сделать выводы о наличии или отсутствии нелинейных связей.  \n",
    "        \n",
    "7.  Провести обработку данных, на основе выводов полученных в прошлых шагах.  \n",
    "   1. провести дополнительную очистку  \n",
    "   2. выполнить нужный тип энкодинга(если требуется)  \n",
    "   3. Сконструировать новые признаки.\n",
    "\n",
    "8. Построить Графики взаимодействия полученных данных с целевым показателем  \n",
    "   1. Для количественных данных линейные графики на нормализованных данных  \n",
    "   2. для категориальных данных с малым количеством категорий построить ScaterPlot во времени  \n",
    "   3. для категориальных данных с большим количеством показателей построить heatmap во времени(обычно строят, только для ризнаков которые показывают высокие коэффициенты корреляции и потенциально интересны, пример такого графика спектрограмма в анализе звука)  \n",
    "9. Сделать выводы на основе проведенного анализа и учитывая особенности планируемой архитектуры модели.  \n",
    "   1. Какие данные и почему нельзя использовать в модели  \n",
    "   2. какие данные можно использовать без преобразования  \n",
    "   3. какие данные можно использовать выполнив преобразование  \n",
    "   4. какие новые признаки нужно использовать и почему  \n",
    "   5. есть ли смысл использовать один набор признаков или построить разные модели на подмножестве признаков и почему.  \n",
    "   6. Выделить итоговый список необходимых данных  \n",
    "10. Описать ожидания от модели на проанализированных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b8da14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lakefs_client import Configuration\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Загружает переменные из .env\n",
    "\n",
    "def get_lakefs_config():\n",
    "    config = Configuration()\n",
    "    config.host = os.getenv(\"LAKEFS_HOST\")\n",
    "    config.username = os.getenv(\"LAKEFS_ACCESS_KEY\")\n",
    "    config.password = os.getenv(\"LAKEFS_SECRET_KEY\")\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0551aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lakefs_client import Configuration\n",
    "from lakefs_client import ApiClient\n",
    "from lakefs_client.api import objects_api\n",
    "\n",
    "def load_dataframe(configuration: Configuration, repository: str, ref: str, path: str):\n",
    "    # Создаем клиента\n",
    "    with ApiClient(configuration) as api_client:\n",
    "        obj_api = objects_api.ObjectsApi(api_client)\n",
    "\n",
    "        # Получаем объект\n",
    "        #repository = \"mfdp-fin-fraud-detection-data\"\n",
    "        #ref = \"main\"  # или другой commit/branch/tag\n",
    "        #path = \"ieee-fraud-detection/sample_submission.csv\"\n",
    "\n",
    "        response = obj_api.get_object(repository, ref, path)\n",
    "        content = response.read()\n",
    "\n",
    "        # Например, если CSV\n",
    "        import pandas as pd\n",
    "        from io import StringIO\n",
    "        df = pd.read_csv(StringIO(content.decode('utf-8')))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4fc7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6c0b664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud\n",
       "0        3663549      0.5\n",
       "1        3663550      0.5\n",
       "2        3663551      0.5\n",
       "3        3663552      0.5\n",
       "4        3663553      0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получаем объект\n",
    "configuration = get_lakefs_config()\n",
    "repository = \"mfdp-fin-fraud-detection-data\"\n",
    "ref = \"main\"  # или другой commit/branch/tag\n",
    "path = \"ieee-fraud-detection/sample_submission.csv\"\n",
    "\n",
    "df = load_dataframe(configuration, repository, ref, path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a236aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
