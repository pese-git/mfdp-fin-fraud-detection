{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260c3a63",
   "metadata": {},
   "source": [
    "**2\\. –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (Data Understanding)**\n",
    "\n",
    "–¶–µ–ª—å —à–∞–≥–∞ ‚Äì –ø–æ–Ω—è—Ç—å —Å–ª–∞–±—ã–µ –∏ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å, –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∏–¥–µ–∏, –∫–∞–∫  \n",
    "–∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å, –∏ –ª—É—á—à–µ –ø–æ–Ω—è—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã –∑–∞–∫–∞–∑—á–∏–∫–∞. –î–ª—è —ç—Ç–æ–≥–æ –º—ã —Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏, –¥–µ–ª–∞–µ–º –≤—ã–±–æ—Ä–∫–∏ –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º  \n",
    "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.\n",
    "\n",
    "2.1 –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (Data collection)  \n",
    "–í—ã–≥—Ä—É–∂–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ (–∏–ª–∏ —Å—Ä–µ–∑ –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –∏—Ö –æ–±—ä–µ–º —Å–ª–∏—à–∫–æ–º –≤–µ–ª–∏–∫) –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.  \n",
    "–í–µ—Ä—Å–∏–æ–Ω–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞–º–∏ DVC.\n",
    "\n",
    "2.2 –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (Data exploration)  \n",
    "–ò—Å—Å–ª–µ–¥—É–µ–º –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≥–∏–ø–æ—Ç–µ–∑—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–æ–≥–æ, –∫–∞–∫ —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ–º–æ–≥—É—Ç —Ä–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É. –ü—Ä–æ–≤–µ—Ä—è–µ–º  \n",
    "–∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "–û—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö:\n",
    "\n",
    "1. –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω—É—é –≤—ã–±–æ—Ä–∫—É –∏–∑ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö  \n",
    "2. –ü—Ä–æ–≤–µ—Å—Ç–∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ–π –≤—ã–±–æ—Ä–∫–∏.  \n",
    "* –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –≤ –∫–∞–∂–¥–æ–º —Å—Ç–æ–ª–±—Ü–µ  \n",
    "* –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ù–æ–º–∏–Ω–∞–ª—å–Ω—ã–µ, –ü–æ—Ä—è–¥–∫–æ–≤—ã–µ)  \n",
    "* –ß–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ, –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ, –∏–Ω—Ç–µ—Ä–≤–∞–ª—å–Ω—ã–µ, –æ—Ç–Ω–æ—à–µ–Ω–∏—è)  \n",
    "* –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∫ –Ω—É–∂–Ω—ã–º —Ç–∏–ø–∞–º  \n",
    "* –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –≤—ã–±—Ä–æ—Å—ã, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è, –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è(–Ω–∞–ø—Ä–∏–º–µ—Ä –≤ —Å–∏—Å—Ç–µ–º–µ —Å–ª—É—á–∏–ª—Å—è —Å–±–æ–π –∏ –≤ –ø–æ–ª–µ —Å –∏–º–µ–Ω–µ–º–ø–æ–ø–∞–ª–∞ –¥–ª–∏–Ω–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞).\n",
    "\n",
    "(–ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å–¥–µ–ª–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é, –æ–±—ã—á–Ω–æ —ç—Ç–æ —Ç–∞–±–ª–∏—á–∫–∞ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ –∏–ª–∏ –∫–∞–∫–æ–π —Ç–æ –∏–∑  \n",
    "–ø—Ä–æ—Ñ–∞–π–ª–µ—Ä–æ–≤)\n",
    "\n",
    "3. –ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ—á–∏—Å—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö (–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è, —É–¥–∞–ª–∏—Ç—å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)  \n",
    "4. –£–¥–∞–ª–∏—Ç—å –∏–∑ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ. (–ª–∏—à–Ω–∏–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã, —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è, –ø–æ–ª—è —Å –æ—á–µ–Ω—å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–Ω–∞—á–µ–Ω–∏–π)  \n",
    "5. –ü—Ä–æ–≤–µ—Å—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö  \n",
    "   1. —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö  \n",
    "   2. –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (—Ç–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞ –≤—ã–±—Ä–∞—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–∞–Ω–Ω—ã—Ö, —á–∞—Å—Ç–æ –ø–æ–ª–µ–∑–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É, –Ω–æ –∏–Ω–æ–≥–¥–∞ –ª—É—á—à–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ª–∏–Ω–µ–π–Ω—ã–º –≥—Ä–∞—Ñ–∏–∫–æ–º –∏–ª–∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–∏ —Å –ø–æ–º–æ—â—å—é scaterplot)  \n",
    "6. –ü—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑  \n",
    "   1. –î–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ü–∏—Ä—Å–æ–Ω–∞  \n",
    "   2. —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Ç—Ä–∏—Ü—ã (–Ω–∞–π—Ç–∏ —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –Ω–∞–π—Ç–∏ –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ª–∏–Ω–µ–π–Ω–æ –≤–ª–∏—è—é—â–∏–µ –Ω–∞ —Ü–µ–ª–µ–≤–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å, –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≥–∏–ø–æ—Ç–µ–∑—ã –ø–æ –∫–æ–Ω—Å—Ç—Ä—É–∏—Ä–æ–≤–∞–Ω–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)  \n",
    "   3. –î–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏ –ø–æ—Ä—è–¥–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö \\- –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –°–ø–∏—Ä–º–µ–Ω–∞  —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –∞–Ω–∞–ª–∏–∑—É, —Ç–æ–ª—å–∫–æ —É—á–µ—Å—Ç—å —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö  \n",
    "   4. –î–ª—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ü—Ñ–∏–∫–∞  \n",
    "   5. –°–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞, —Å–¥–µ–ª–∞—Ç—å –æ—Ü–µ–Ω–∫—É –º–µ–∂–¥—É –≤—Å–µ–º–∏ —Ç–∏–ø–∞–º–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏(–Ω–∞ –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö),  \n",
    "   6. –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –Ω–∞–π—Ç–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–∏—è–º.  \n",
    "   7. –°–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã –æ –Ω–∞–ª–∏—á–∏–∏ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö —Å–≤—è–∑–µ–π.  \n",
    "        \n",
    "7.  –ü—Ä–æ–≤–µ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö, –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–≤–æ–¥–æ–≤ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –≤ –ø—Ä–æ—à–ª—ã—Ö —à–∞–≥–∞—Ö.  \n",
    "   1. –ø—Ä–æ–≤–µ—Å—Ç–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –æ—á–∏—Å—Ç–∫—É  \n",
    "   2. –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω—É–∂–Ω—ã–π —Ç–∏–ø —ç–Ω–∫–æ–¥–∏–Ω–≥–∞(–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)  \n",
    "   3. –°–∫–æ–Ω—Å—Ç—Ä—É–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.\n",
    "\n",
    "8. –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ì—Ä–∞—Ñ–∏–∫–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —Ü–µ–ª–µ–≤—ã–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–º  \n",
    "   1. –î–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ª–∏–Ω–µ–π–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö  \n",
    "   2. –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ—Å—Ç—Ä–æ–∏—Ç—å ScaterPlot –≤–æ –≤—Ä–µ–º–µ–Ω–∏  \n",
    "   3. –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –ø–æ—Å—Ç—Ä–æ–∏—Ç—å heatmap –≤–æ –≤—Ä–µ–º–µ–Ω–∏(–æ–±—ã—á–Ω–æ —Å—Ç—Ä–æ—è—Ç, —Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –≤—ã—Å–æ–∫–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã, –ø—Ä–∏–º–µ—Ä —Ç–∞–∫–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞ –≤ –∞–Ω–∞–ª–∏–∑–µ –∑–≤—É–∫–∞)  \n",
    "9. –°–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ —É—á–∏—Ç—ã–≤–∞—è –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ø–ª–∞–Ω–∏—Ä—É–µ–º–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏.  \n",
    "   1. –ö–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏ –ø–æ—á–µ–º—É –Ω–µ–ª—å–∑—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –º–æ–¥–µ–ª–∏  \n",
    "   2. –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–µ–∑ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è  \n",
    "   3. –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—ã–ø–æ–ª–Ω–∏–≤ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ  \n",
    "   4. –∫–∞–∫–∏–µ –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏ –ø–æ—á–µ–º—É  \n",
    "   5. –µ—Å—Ç—å –ª–∏ —Å–º—ã—Å–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–ª–∏ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –ø–æ—á–µ–º—É.  \n",
    "   6. –í—ã–¥–µ–ª–∏—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö  \n",
    "10. –û–ø–∏—Å–∞—Ç—å –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8da14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lakefs_client import Configuration\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env\n",
    "\n",
    "def get_lakefs_config():\n",
    "    config = Configuration()\n",
    "    config.host = os.getenv(\"LAKEFS_HOST\")\n",
    "    config.username = os.getenv(\"LAKEFS_ACCESS_KEY\")\n",
    "    config.password = os.getenv(\"LAKEFS_SECRET_KEY\")\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0551aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lakefs_client import Configuration\n",
    "from lakefs_client import ApiClient\n",
    "from lakefs_client.api import objects_api\n",
    "\n",
    "def load_dataframe(configuration: Configuration, repository: str, ref: str, path: str):\n",
    "    # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞\n",
    "    with ApiClient(configuration) as api_client:\n",
    "        obj_api = objects_api.ObjectsApi(api_client)\n",
    "\n",
    "        # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç\n",
    "        #repository = \"mfdp-fin-fraud-detection-data\"\n",
    "        #ref = \"main\"  # –∏–ª–∏ –¥—Ä—É–≥–æ–π commit/branch/tag\n",
    "        #path = \"ieee-fraud-detection/sample_submission.csv\"\n",
    "\n",
    "        response = obj_api.get_object(repository, ref, path)\n",
    "        content = response.read()\n",
    "\n",
    "        # –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ CSV\n",
    "        import pandas as pd\n",
    "        from io import StringIO\n",
    "        df = pd.read_csv(StringIO(content.decode('utf-8')))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç\n",
    "configuration = get_lakefs_config()\n",
    "repository = \"mfdp-fin-fraud-detection-data\"\n",
    "ref = \"main\"  # –∏–ª–∏ –¥—Ä—É–≥–æ–π commit/branch/tag\n",
    "path_input = \"ieee-fraud-detection/sample_submission.csv\"\n",
    "\n",
    "df = load_dataframe(configuration, repository, ref, path_input)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lakefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a236aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lakefs\n",
    "from lakefs.client import Client\n",
    "import pandas as pd\n",
    "\n",
    "clt = Client(\n",
    "    host=os.getenv(\"LAKEFS_HOST\"),\n",
    "    username=os.getenv(\"LAKEFS_ACCESS_KEY\"),\n",
    "    password=os.getenv(\"LAKEFS_SECRET_KEY\"),\n",
    ")\n",
    "\n",
    "# –£–∫–∞–∂–∏—Ç–µ –∏–º—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –∏ –≤–µ—Ç–∫–∏\n",
    "repo_name = \"mfdp-fin-fraud-detection-data\"\n",
    "branch_name = \"main\"\n",
    "file_path = \"ieee-fraud-detection/sample_submission.csv\"\n",
    "\n",
    "# –ü–æ–ª—É—á–∏—Ç–µ –æ–±—ä–µ–∫—Ç —Ñ–∞–π–ª–∞\n",
    "obj = lakefs.repository(repo_name, client=clt).branch(branch_name).object(path=file_path)\n",
    "\n",
    "# –ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞\n",
    "with obj.reader(mode='r') as file:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32136a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read into pandas directly by supplying the lakeFS URI...\n",
    "sample_submission = pd.read_csv(f\"lakefs://mfdp-fin-fraud-detection-data/main/ieee-fraud-detection/sample_submission.csv\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b3961",
   "metadata": {},
   "source": [
    "# 1. create_lakefs_branch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "LAKEFS_ENDPOINT = os.getenv(\"LAKEFS_ENDPOINT\")\n",
    "LAKEFS_REPO = os.getenv(\"LAKEFS_REPO\")\n",
    "LAKEFS_BRANCH = os.getenv(\"LAKEFS_BRANCH\", \"processing_branch\")\n",
    "LAKEFS_ACCESS_KEY = os.getenv(\"LAKEFS_ACCESS_KEY\")\n",
    "LAKEFS_SECRET_KEY = os.getenv(\"LAKEFS_SECRET_KEY\")\n",
    "\n",
    "def create_lakefs_branch():\n",
    "    auth = HTTPBasicAuth(LAKEFS_ACCESS_KEY, LAKEFS_SECRET_KEY)\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    branch_url = f\"{LAKEFS_ENDPOINT}/api/v1/repositories/{LAKEFS_REPO}/branches\"\n",
    "\n",
    "    # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å –≤–µ—Ç–∫—É\n",
    "    resp = requests.post(branch_url, json={\"name\": LAKEFS_BRANCH, \"source\": \"main\"}, auth=auth, headers=headers)\n",
    "\n",
    "    if resp.status_code == 201:\n",
    "        print(f\"‚úÖ Branch '{LAKEFS_BRANCH}' created successfully.\")\n",
    "    elif resp.status_code == 409:\n",
    "        print(f\"‚ö†Ô∏è Branch '{LAKEFS_BRANCH}' already exists.\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to create branch: {resp.status_code}\")\n",
    "        print(resp.text)\n",
    "        return\n",
    "\n",
    "    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤–µ—Ç–æ–∫\n",
    "    list_resp = requests.get(branch_url, auth=auth)\n",
    "    print(\"üìÇ Available branches:\")\n",
    "    for branch in list_resp.json().get(\"results\", []):\n",
    "        print(\" -\", branch['id'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_lakefs_branch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e9c7a",
   "metadata": {},
   "source": [
    "# 2. data_preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbd0cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lakefs_client import Configuration\n",
    "from lakefs_client import ApiClient\n",
    "from lakefs_client.api import objects_api\n",
    "\n",
    "def load_dataframe(configuration: Configuration, repository: str, ref: str, path: str):\n",
    "    # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞\n",
    "    with ApiClient(configuration) as api_client:\n",
    "        obj_api = objects_api.ObjectsApi(api_client)\n",
    "\n",
    "        response = obj_api.get_object(repository, ref, path)\n",
    "        content = response.read()\n",
    "\n",
    "        # –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ CSV\n",
    "        import pandas as pd\n",
    "        from io import StringIO\n",
    "        df = pd.read_csv(StringIO(content.decode('utf-8')))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47960afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from lakefs_client import Configuration, ApiClient\n",
    "from lakefs_client.api.objects_api import ObjectsApi\n",
    "from lakefs_client.models import ObjectStats\n",
    "from lakefs_client.rest import ApiException\n",
    "\n",
    "def save_dataframe(df: pd.DataFrame, configuration: Configuration, repository: str, ref: str, path: str):\n",
    "    try:\n",
    "        with ApiClient(configuration) as api_client:\n",
    "            obj_api = ObjectsApi(api_client)\n",
    "\n",
    "            buffer = BytesIO()\n",
    "            df.to_csv(buffer, index=False)\n",
    "            buffer.seek(0)\n",
    "\n",
    "            # –î–æ–±–∞–≤–ª—è–µ–º –∞—Ç—Ä–∏–±—É—Ç .name (–∏–º–∏—Ç–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞)\n",
    "            buffer.name = path.split('/')[-1]\n",
    "\n",
    "            obj_api.upload_object(\n",
    "                repository=repository,\n",
    "                branch=ref,\n",
    "                path=path,\n",
    "                content=buffer\n",
    "            )\n",
    "\n",
    "            print(f\"‚úÖ DataFrame saved to lakeFS at {repository}/{ref}/{path}\")\n",
    "    except ApiException as e:\n",
    "        print(f\"‚ùå Failed to upload object: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb913727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "def clean_data(df: pd.DataFrame):\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ DataFrame –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è df)\n",
    "    #df = pd.read_csv('your_data.csv')\n",
    "    df = df_cleaned\n",
    "\n",
    "    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞\n",
    "    missing_percentage = df.isnull().mean() * 100\n",
    "\n",
    "    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ª–±—Ü—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –º–µ–Ω—å—à–µ 90% –ø—Ä–æ–ø—É—Å–∫–æ–≤\n",
    "    df_cleaned = df.loc[:, missing_percentage < 90]\n",
    "\n",
    "    # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —á–∏—Å–ª–æ–≤—ã–µ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã\n",
    "    numerical_cols = df_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "    categorical_cols = df_cleaned.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # –ò–º–ø—É—Ç–∞—Ü–∏—è –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ (–∑–∞–º–µ–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–∞ –º–µ–¥–∏–∞–Ω—É)\n",
    "    numerical_imputer = SimpleImputer(strategy='median')\n",
    "    df_cleaned[numerical_cols] = numerical_imputer.fit_transform(df_cleaned[numerical_cols])\n",
    "\n",
    "    # –ò–º–ø—É—Ç–∞—Ü–∏—è –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ (–∑–∞–º–µ–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–∞ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)\n",
    "    categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df_cleaned[categorical_cols] = categorical_imputer.fit_transform(df_cleaned[categorical_cols])\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3df0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "\n",
    "def encoder_data(df: pd.DataFrame):\n",
    "    # –ï—Å–ª–∏ –≤ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–∞—Ö –µ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –º–æ–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏—Ö –≤ —á–∏—Å–ª–æ–≤—ã–µ –∏–ª–∏ —É–¥–∞–ª–∏—Ç—å.\n",
    "    # –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ 'category' - –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è, –º–æ–∂–Ω–æ –µ–µ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å.\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # –ü—Ä–∏–º–µ–Ω—è–µ–º LabelEncoder –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    encoder = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = encoder.fit_transform(df[col].astype(str))  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫–∏ –ø–µ—Ä–µ–¥ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a8ad8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(df: pd.DataFrame):\n",
    "    # –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–æ–±–∞–≤–∏–º —Ñ–∏—á—É –∫–∞–∫ –ª–æ–≥–∞—Ä–∏—Ñ–º —á–∏—Å–ª–æ–≤–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞\n",
    "    if 'feature' in df.columns:\n",
    "        df['log_feature'] = df['feature'].apply(lambda x: np.log(x + 1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "LAKEFS_ENDPOINT = os.getenv(\"LAKEFS_ENDPOINT\")\n",
    "LAKEFS_REPO = os.getenv(\"LAKEFS_REPO\")\n",
    "LAKEFS_BRANCH = os.getenv(\"LAKEFS_BRANCH\", \"processing_branch\")\n",
    "LAKEFS_ACCESS_KEY = os.getenv(\"LAKEFS_ACCESS_KEY\")\n",
    "LAKEFS_SECRET_KEY = os.getenv(\"LAKEFS_SECRET_KEY\")\n",
    "\n",
    "path_train_transaction_input = \"ieee-fraud-detection/train_transaction.csv\"\n",
    "path_train_identity_input = \"ieee-fraud-detection/train_identity.csv\"\n",
    "\n",
    "path_output = \"ieee-fraud-detection/clean_merge_dataset.csv\"\n",
    "\n",
    "\n",
    "def get_lakefs_config():\n",
    "    config = Configuration()\n",
    "    config.host = os.getenv(\"LAKEFS_HOST\")\n",
    "    config.username = os.getenv(\"LAKEFS_ACCESS_KEY\")\n",
    "    config.password = os.getenv(\"LAKEFS_SECRET_KEY\")\n",
    "    return config\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data():\n",
    "    # –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV\n",
    "    #df = pd.read_csv(INPUT_URI)\n",
    "    configuration = get_lakefs_config()\n",
    "    df_train_transaction = load_dataframe(configuration, LAKEFS_REPO, LAKEFS_BRANCH, path_train_transaction_input)\n",
    "    print(f\"‚úÖ DataFrame transactions loaded frome lakeFS at {LAKEFS_REPO}/{LAKEFS_BRANCH}/{path_train_transaction_input}\")\n",
    "\n",
    "    df_train_identity = load_dataframe(configuration, LAKEFS_REPO, LAKEFS_BRANCH, path_train_identity_input)\n",
    "    print(f\"‚úÖ DataFrame identity loaded frome lakeFS at {LAKEFS_REPO}/{LAKEFS_BRANCH}/{path_train_identity_input}\")\n",
    "    \n",
    "    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ TransactionID\n",
    "    df = df_train_transaction.merge(df_train_identity, on=\"TransactionID\", how=\"left\")\n",
    "    print(f\"‚úÖ DataFrames transactions and identity merged\")\n",
    "\n",
    "    # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö (—É–¥–∞–ª—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏)\n",
    "    df = clean_data(df)\n",
    "    \n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "    df = encoder_data(df)\n",
    "    \n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏—á–µ–π (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)\n",
    "    df = impute_data(df)\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    save_dataframe(df, configuration, LAKEFS_REPO, LAKEFS_BRANCH, path_output)\n",
    "\n",
    "    print(f\"Processed data saved to {path_output}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afcccc8",
   "metadata": {},
   "source": [
    "# 3. validate_processed_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bed86938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lakefs_client import Configuration\n",
    "from lakefs_client import ApiClient\n",
    "from lakefs_client.api import objects_api\n",
    "\n",
    "def load_dataframe(configuration: Configuration, repository: str, ref: str, path: str):\n",
    "    # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞\n",
    "    with ApiClient(configuration) as api_client:\n",
    "        obj_api = objects_api.ObjectsApi(api_client)\n",
    "\n",
    "        response = obj_api.get_object(repository, ref, path)\n",
    "        content = response.read()\n",
    "\n",
    "        # –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ CSV\n",
    "        import pandas as pd\n",
    "        from io import StringIO\n",
    "        df = pd.read_csv(StringIO(content.decode('utf-8')))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75b56a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in data\n",
      "Data types: \n",
      "TransactionID      int64\n",
      "isFraud          float64\n",
      "dtype: object\n",
      "Data statistics: \n",
      "       TransactionID   isFraud\n",
      "count   5.066910e+05  506691.0\n",
      "mean    3.916894e+06       0.5\n",
      "std     1.462692e+05       0.0\n",
      "min     3.663549e+06       0.5\n",
      "25%     3.790222e+06       0.5\n",
      "50%     3.916894e+06       0.5\n",
      "75%     4.043566e+06       0.5\n",
      "max     4.170239e+06       0.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path_input = \"ieee-fraud-detection/clean_merge_dataset.csv\"\n",
    "\n",
    "def validate_data():\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    configuration = get_lakefs_config()\n",
    "    df = load_dataframe(configuration, LAKEFS_REPO, LAKEFS_BRANCH, path_input)\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∏\n",
    "    if df.isnull().sum().any():\n",
    "        print(\"Warning: Data contains missing values\")\n",
    "    else:\n",
    "        print(\"No missing values in data\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "    print(f\"Data types: \\n{df.dtypes}\")\n",
    "    \n",
    "    # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "    print(f\"Data statistics: \\n{df.describe()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    validate_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf31dc",
   "metadata": {},
   "source": [
    "## 4. commit_preprocessed_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d539a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Commit completed. ID: d16d6c4809525b8a12e4700fcbc2e51d3578407b6ab4f49d207ce7ffdd0eda2e\n"
     ]
    }
   ],
   "source": [
    "from lakefs_client import Configuration, ApiClient\n",
    "from lakefs_client.api.commits_api import CommitsApi\n",
    "from lakefs_client.models import CommitCreation\n",
    "\n",
    "import os\n",
    "\n",
    "# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "LAKEFS_REPO = os.getenv(\"LAKEFS_REPO\")\n",
    "LAKEFS_BRANCH = os.getenv(\"LAKEFS_BRANCH\", \"processing_branch\")\n",
    "LAKEFS_ACCESS_KEY = os.getenv(\"LAKEFS_ACCESS_KEY\")\n",
    "LAKEFS_SECRET_KEY = os.getenv(\"LAKEFS_SECRET_KEY\")\n",
    "LAKEFS_HOST = os.getenv(\"LAKEFS_HOST\")\n",
    "\n",
    "\n",
    "def get_lakefs_config():\n",
    "    config = Configuration()\n",
    "    config.host = LAKEFS_HOST\n",
    "    config.username = LAKEFS_ACCESS_KEY\n",
    "    config.password = LAKEFS_SECRET_KEY\n",
    "    return config\n",
    "\n",
    "\n",
    "def commit_processed_data():\n",
    "    configuration = get_lakefs_config()\n",
    "    \n",
    "    with ApiClient(configuration) as api_client:\n",
    "        commit_api = CommitsApi(api_client)\n",
    "\n",
    "        commit = CommitCreation(\n",
    "            message=\"üíæ Added cleaned sample_submission.csv after preprocessing\"\n",
    "        )\n",
    "\n",
    "        response = commit_api.commit(\n",
    "            repository=LAKEFS_REPO,\n",
    "            branch=LAKEFS_BRANCH,\n",
    "            commit_creation=commit\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ Commit completed. ID: {response.id}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    commit_processed_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf4605",
   "metadata": {},
   "source": [
    "## 5. train_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "730e07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lakefs_client import Configuration\n",
    "from lakefs_client import ApiClient\n",
    "from lakefs_client.api import objects_api\n",
    "\n",
    "def load_dataframe(configuration: Configuration, repository: str, ref: str, path: str):\n",
    "    # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞\n",
    "    with ApiClient(configuration) as api_client:\n",
    "        obj_api = objects_api.ObjectsApi(api_client)\n",
    "\n",
    "        response = obj_api.get_object(repository, ref, path)\n",
    "        content = response.read()\n",
    "\n",
    "        # –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ CSV\n",
    "        import pandas as pd\n",
    "        from io import StringIO\n",
    "        df = pd.read_csv(StringIO(content.decode('utf-8')))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653dbf5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['target'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m     mlflow.end_run()\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     15\u001b[39m configuration = get_lakefs_config()\n\u001b[32m     16\u001b[39m df = load_dataframe(configuration, LAKEFS_REPO, LAKEFS_BRANCH, path_input)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m X = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtarget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m y = df[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MLflow\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Karpov.Courses/mfdp-fin-fraud-detection/.venv/lib/python3.11/site-packages/pandas/core/frame.py:5581\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5434\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5435\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5442\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5443\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5444\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5445\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5446\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5579\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5583\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5587\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5588\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Karpov.Courses/mfdp-fin-fraud-detection/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4788\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4786\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4788\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4791\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Karpov.Courses/mfdp-fin-fraud-detection/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4830\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4828\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4829\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4830\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4831\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4833\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4834\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Karpov.Courses/mfdp-fin-fraud-detection/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:7070\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7068\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7071\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['target'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "#OUTPUT_URI = os.getenv(\"OUTPUT_URI\")\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "\n",
    "path_input = \"ieee-fraud-detection/clean_merge_dataset.csv\"\n",
    "\n",
    "def train_model():\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    configuration = get_lakefs_config()\n",
    "    df = load_dataframe(configuration, LAKEFS_REPO, LAKEFS_BRANCH, path_input)\n",
    "    \n",
    "    X = df.drop(\"target\", axis=1)\n",
    "    y = df[\"target\"]\n",
    "    \n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MLflow\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    mlflow.start_run()\n",
    "\n",
    "    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    auc = roc_auc_score(y, model.predict_proba(X)[:, 1])\n",
    "\n",
    "    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∏ –º–æ–¥–µ–ª–∏\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    # –ó–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–ø—É—Å–∫\n",
    "    mlflow.end_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ee929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
